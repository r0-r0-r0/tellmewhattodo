<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction - Tell Me What to Do</title>
    <link rel="stylesheet" href="style.css" />

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100..900;1,100..900&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <div class="page-wrapper">
      <a href="index.html" class="close-button">√ó</a>
      <div class="text-wrapper">
       <div class="content-section">
  <div class="text-huge">Podcasts</div>

  <div class="podcast">
    <h2>1. Who Owns Our Digital Alternatives</h2><br>
    <p>
      These days, so much of our lives takes place online ‚Äî but what about our afterlives? A recent study by the Oxford Internet Institute predicts that the number of deceased Facebook users could outnumber the living by 2070. As AI advances, a debate is growing over digital remains and what should be done with the vast amounts of data we leave behind.
    </p>
    <p>
      In this episode, Carl √ñhman, author of <em>The Afterlife of Data: What Happens to Your Information When You Die and Why You Should Care</em>, explores the ethics, politics, and future of our digital identities. Named one of The Economist's Best Books of 2024, √ñhman‚Äôs work sheds light on who truly owns our data after death ‚Äî and whether we should have a say in our digital legacy.
    </p>
    <p>
      Carl √ñhman is an assistant professor of political science at Uppsala University, Sweden. His research spans several topics, including the politics and ethics of AI, deepfakes and digital remains.
    </p>
    <p>
      He is joined in conversation by Stephanie Hare, researcher, broadcaster, and author of <em>Technology is Not Neutral: A Short Guide to Technology Ethics</em>.
    </p>
    <p>
      <a href="https://podcasts.apple.com/nl/podcast/who-owns-our-digital-afterlives-with-carl-%C3%B6hman/id708371900?i=1000701573139" target="_blank">
        üéß Listen to the episode
      </a>
    </p>
  </div>

  <div class="podcast">
    <h2>2. Who Do We Become When We Talk To Machines?</h2><br>
    <p>
      In recent years, programs (robots and chatbots) built on generative AI have offered themselves as companions that care ‚Äî presented, for example, as potential coaches, psychotherapists, and romantic companions ‚Äî as artificial intimacy, our new AI.
    </p>
    <p>
      A study of users of these programs makes it clear that adjacent to the question of what these programs can do is another: What are they doing to us ‚Äî for example, to the way we think about human intimacy, agency, and empathy?
    </p>
    <p>
      <a href="https://mit-genai.pubpub.org/pub/uawlth3j/release/2" target="_blank">
        üìÑ Read the article
      </a>
    </p>
  </div>

  <div class="podcast"><br>
    <h2>3. How Our Relationships Are Changing in the Age of "Artificial Intimacy"</h2>
    <p><br>
      Early adopters are flocking to AI bots for therapy, friendship, even love. How will these relationships impact us? MIT sociologist Sherry Turkle delves into her new research on "artificial intimacy." Later in the episode, host Manoush Zomorodi speaks with Somnium Space founder Artur Sychov.
    </p>
    <p>
      Note: A few weeks ago, we talked to Sherry Turkle in a Body Electric episode called <em>"If a bot relationship FEELS real, should we care that it's not?"</em> Today's episode is an even deeper dive into that conversation with Sherry.
    </p>
  </div><br>

  <div class ="text-huge">Movies</div>

    <p>
      <strong>Companion</strong> ‚Äî <a href="https://www.imdb.com/title/tt26584495" target="_blank">üé¨ View on IMDb</a>
    </p>
  <br>

  <div class="text-huge">Articles</div>
  <ul>
    <p>Ranked: All the Things People Use AI for in 2025</p>
    <p>‚ÄúGo To Therapy‚Äù</p>
    <p>Meta‚Äôs ‚ÄòDigital Companions‚Äô Will Talk Sex With Users‚ÄîEven Children</p>
    <p>First Amendment doesn‚Äôt just protect human speech, chatbot maker argues</p>
    <p>Woman Files for Divorce After ChatGPT ‚ÄòReads‚Äô Husband‚Äôs Affair in Coffee Cup</p>
    <p>AI chatbots do battle over human memories</p>
    <p>AI suggest suicide</p>
    <p>WHAT AI THINKS IT KNOWS ABOUT YOU</p>
    <p>Eliza psychotherapist</p>
    <p>Salsabila, V., Awaludin, L., &amp; Assiddiqi, H. (2022). REFUTATION OF LAURA MULVEY'S 'MALE GAZE' THEORY IN FILM LITTLE WOMEN (2019). Saksama: Jurnal Sastra, 1(2), 100-118.</p>
    <p>Fahner, C. Inverting the Algorithmic Gaze: Confronting Platform Power Through Media Artworks (Doctoral dissertation, Toronto Metropolitan University).</p>
    <p>Teo, S. A. (2025). Artificial intelligence, human vulnerability and multi-level resilience. Computer Law &amp; Security Review, 57, 106134.</li>
    <p>Abdulai, A. F. (2025). Is Generative AI Increasing the Risk for Technology‚ÄêMediated Trauma Among Vulnerable Populations?. Nursing Inquiry, 32(1), e12686.</li>
    <p>Patulny, R., Lazarevic, N., &amp; Smith, V. (2020). ‚ÄòOnce more, with feeling,‚Äô said the robot: AI, the end of work and the rise of emotional economies. Emotions and Society, 2(1), 79-97.</li>
    <p>Teo, S. A. (2024). How to think about freedom of thought (and opinion) in the age of AI. Computer Law &amp; Security Review, 53, 105969.</li>
  </ul><br>

  <div class="text-huge">AI Policy</div>
  <ul>
    <p>Cognitive freedom and legal accountability: Rethinking the EU AI act‚Äôs theoretical approach to manipulative AI as unacceptable risk</p>
    <p>Commission finds Apple and Meta in breach of the Digital Markets Act</p>
  </ul>
</div>

        </div>
      </div>
      <div class="floating-menu">
        <ul class="menu-list">
          <li><a href="introduction.html">Introduction</a></li>
          <li><a href="bio.html">Bio</a></li>
          <li><a href="podcasts.html">Podcasts & Articles</a></li>
          <li><a href="critique.html">A Feminist Critique</a></li>
        </ul>
        <button class="menu-btn">?</button>
      </div>
    </div>

    <script>
      const menuBtn = document.querySelector(".menu-btn");
      const menuList = document.querySelector(".menu-list");

      // Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú Î©îÎâ¥ ÌÜ†Í∏Ä
      menuBtn.addEventListener("click", (event) => {
        event.stopPropagation(); // Ïô∏Î∂Ä ÌÅ¥Î¶≠ Í∞êÏßÄ Î∞©ÏßÄ
        menuList.style.display =
          menuList.style.display === "flex" ? "none" : "flex";
      });

      // Î©îÎâ¥ ÌÅ¥Î¶≠ Ïãú Îã´ÌûàÏßÄ ÏïäÍ≤å
      menuList.addEventListener("click", (event) => {
        event.stopPropagation();
      });

      // Ïô∏Î∂Ä ÌÅ¥Î¶≠ Ïãú Î©îÎâ¥ Îã´Í∏∞
      document.addEventListener("click", () => {
        menuList.style.display = "none";
      });
    </script>
  </body>
</html>
